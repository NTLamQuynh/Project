
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import joblib


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

def load_dataset():
    """
    T·ª± sinh ra m·ªôt dataset m√¥ ph·ªèng h√†nh vi kh√°ch h√†ng online.
    C·ªôt nh√£n: Revenue (1 = c√≥ mua, 0 = kh√¥ng mua).
    Kh√¥ng c·∫ßn internet, kh√¥ng c·∫ßn ƒë·ªçc CSV.
    """
    np.random.seed(42)
    n = 5000  # s·ªë kh√°ch h√†ng

    # C√°c c·ªôt s·ªë (numeric)
    administrative = np.random.randint(0, 10, size=n) #xem h√†nh ch√≠nh
    administrative_duration = np.random.exponential(scale=60, size=n)  # ph√∫t
    informational = np.random.randint(0, 5, size=n)
    informational_duration = np.random.exponential(scale=30, size=n)
    product_related = np.random.randint(1, 50, size=n)
    product_related_duration = np.random.exponential(scale=300, size=n)
    bounce_rates = np.random.uniform(0, 0.2, size=n)
    exit_rates = np.random.uniform(0, 0.3, size=n)
    page_values = np.random.exponential(scale=20, size=n)
    special_day = np.random.choice([0.0, 0.2, 0.4, 0.6, 0.8], size=n)

    # C√°c c·ªôt ph√¢n lo·∫°i (categorical)
    months = ["Jan", "Feb", "Mar", "Apr", "May", "June", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]
    month = np.random.choice(months, size=n)

    operating_systems = np.random.randint(1, 5, size=n)
    browser = np.random.randint(1, 6, size=n)
    region = np.random.randint(1, 10, size=n)
    traffic_type = np.random.randint(1, 20, size=n)

    visitor_types = ["New_Visitor", "Returning_Visitor", "Other"]
    visitor_type = np.random.choice(visitor_types, size=n)

    weekend = np.random.choice([True, False], size=n)

    # T·∫°o x√°c su·∫•t mua h√†ng (probability) d·ª±a tr√™n v√†i ƒë·∫∑c tr∆∞ng
    # logic: kh√°ch xem nhi·ªÅu s·∫£n ph·∫©m, page_values cao, returning_visitor, cu·ªëi tu·∫ßn, special_day cao ‚Üí d·ªÖ mua h∆°n
    base_prob = 0.1
    #x√°c su·∫•t kh√°ch s·∫Ω mua h√†ng
    prob = (
        base_prob
        + 0.003 * product_related
        + 0.01 * (page_values / (1 + page_values))
        + 0.05 * (visitor_type == "Returning_Visitor").astype(float)
        + 0.03 * weekend.astype(float)
        + 0.04 * special_day
        - 0.2 * bounce_rates
        - 0.1 * exit_rates
    )

    # √©p v·ªÅ [0, 0.95]
    prob = np.clip(prob, 0, 0.95)

    # Revenue ~ Bernoulli(prob)
    revenue = np.random.binomial(1, prob, size=n)

    data = {
        "Administrative": administrative,
        "Administrative_Duration": administrative_duration,
        "Informational": informational,
        "Informational_Duration": informational_duration,
        "ProductRelated": product_related,
        "ProductRelated_Duration": product_related_duration,
        "BounceRates": bounce_rates,
        "ExitRates": exit_rates,
        "PageValues": page_values,
        "SpecialDay": special_day,
        "Month": month,
        "OperatingSystems": operating_systems,
        "Browser": browser,
        "Region": region,
        "TrafficType": traffic_type,
        "VisitorType": visitor_type,
        "Weekend": weekend,
        "Revenue": revenue,
    }

    df = pd.DataFrame(data)
    return df


def explore_data(df):
    print("\n=== 5 d√≤ng ƒë·∫ßu ===")
    print(df.head())

    print("\n=== Th√¥ng tin ===")
    print(df.info())

    print("\n=== Th·ªëng k√™ m√¥ t·∫£ (c√°c c·ªôt s·ªë) ===")
    print(df.describe())

    print("\n=== T·ª∑ l·ªá mua h√†ng (Revenue) ===")
    print(df["Revenue"].value_counts())

    # V·∫Ω t·ª∑ l·ªá class
    df["Revenue"].value_counts().plot(kind="bar")
    plt.title("T·ª∑ l·ªá kh√°ch mua / kh√¥ng mua")
    plt.xticks(rotation=0)
    plt.show()

    # Heatmap t∆∞∆°ng quan
    plt.figure(figsize=(12, 8))
    corr = df.corr(numeric_only=True)
    sns.heatmap(corr, annot=False)
    plt.title("Ma tr·∫≠n t∆∞∆°ng quan (c√°c c·ªôt s·ªë)")
    plt.show()


# =======================
# 3. CHU·∫®N B·ªä D·ªÆ LI·ªÜU
# =======================
def prepare_data(df):
    """
    - T√°ch X (features) v√† y (label)
    - X√°c ƒë·ªãnh c·ªôt s·ªë, c·ªôt ph√¢n lo·∫°i
    - T·∫°o preprocessor: scale c·ªôt s·ªë, one-hot c·ªôt ph√¢n lo·∫°i
    """
    # y l√† c·ªôt Revenue, convert True/False -> 1/0
    y = df["Revenue"].astype(int)
    X = df.drop("Revenue", axis=1)

    # Ch·ªçn c·ªôt s·ªë v√† c·ªôt ph√¢n lo·∫°i
    numerical_cols = X.select_dtypes(include=["int64", "float64"]).columns
    categorical_cols = X.select_dtypes(include=["object", "bool"]).columns

    print("\nC·ªôt s·ªë:", list(numerical_cols))
    print("C·ªôt ph√¢n lo·∫°i:", list(categorical_cols))

    # Preprocessor: chu·∫©n h√≥a s·ªë + one-hot cho ph√¢n lo·∫°i
    preprocessor = ColumnTransformer(
        transformers=[
            ("num", StandardScaler(), numerical_cols),
            ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_cols),
        ]
    )

    return X, y, preprocessor


# =======================
# 4. TRAIN NHI·ªÄU MODEL
# =======================
def train_models(preprocessor, X_train, y_train):
    """
    T·∫°o 3 model:
    - Logistic Regression
    - Random Forest
    - XGBoost
    T·∫•t c·∫£ ƒë·ªÅu ƒëi qua b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω (preprocessor).
    """
    models = {
        "Logistic Regression": LogisticRegression(max_iter=500),
        "Random Forest": RandomForestClassifier(n_estimators=150, random_state=42),
        "XGBoost": XGBClassifier(
            use_label_encoder=False, 
            eval_metric="logloss", 
            random_state=42
        ),
    }

    trained = {}

    for name, model in models.items():
        # Pipeline: preprocessor -> model
        clf = Pipeline(
            steps=[
                ("preprocess", preprocessor),
                ("model", model),
            ]
        )

        print(f"\nƒêang train model: {name} ...")
        clf.fit(X_train, y_train)
        print(f"Ho√†n t·∫•t train model: {name}")
        trained[name] = clf

    return trained


# =======================
# 5. ƒê√ÅNH GI√Å
# =======================
def evaluate(trained, X_test, y_test):
    """
    In accuracy, classification_report v√† confusion matrix
    cho t·ª´ng model trong dict trained.
    """
    for name, model in trained.items():
        print("\n==========================")
        print(f"ƒê√ÅNH GI√Å MODEL: {name}")
        print("==========================")

        y_pred = model.predict(X_test)

        print("Accuracy:", accuracy_score(y_test, y_pred))
        print("\nClassification report:")
        print(classification_report(y_test, y_pred))

        # Confusion matrix
        cm = confusion_matrix(y_test, y_pred)
        sns.heatmap(cm, annot=True, fmt="d")
        plt.title(f"Confusion Matrix ‚Äì {name}")
        plt.xlabel("Predicted")
        plt.ylabel("True")
        plt.show()


# =======================
# 6. D·ª∞ ƒêO√ÅN 1 KH√ÅCH H√ÄNG M·ªöI
# =======================
def predict_single(model):
    """
    D·ª± ƒëo√°n cho 1 kh√°ch h√†ng gi·∫£ ƒë·ªãnh (hard-code s·∫µn).
    B·∫°n c√≥ th·ªÉ s·ª≠a c√°c gi√° tr·ªã trong dict sample.
    """

    sample = {
        "Administrative": 3,
        "Administrative_Duration": 60,
        "Informational": 0,
        "Informational_Duration": 0,
        "ProductRelated": 20,
        "ProductRelated_Duration": 500,
        "BounceRates": 0.02,
        "ExitRates": 0.04,
        "PageValues": 30,
        "SpecialDay": 0.5,
        "Month": "Dec",
        "OperatingSystems": 3,
        "Browser": 2,
        "Region": 1,
        "TrafficType": 3,
        "VisitorType": "Returning_Visitor",
        "Weekend": True,
    }

    # ƒê∆∞a v√†o DataFrame 1 h√†ng cho ƒë√∫ng format
    df_sample = pd.DataFrame([sample])

    pred = model.predict(df_sample)[0]
    print("\n=== D·ª∞ ƒêO√ÅN M·∫™U M·ªöI ===")
    print("Input:", sample)
    print("K·∫øt qu·∫£ d·ª± ƒëo√°n:", "C√ì MUA" if pred == 1 else "KH√îNG MUA")


# =======================
# 7. MAIN
# =======================
def main():
   
    df = load_dataset()
    explore_data(df)

    X, y, preprocessor = prepare_data(df)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    trained = train_models(preprocessor, X_train, y_train)

    evaluate(trained, X_test, y_test)

    # Ch·ªçn model t·ªët nh·∫•t (v√≠ d·ª• XGBoost)
    best_model = trained["XGBoost"]

    # üëâ T·∫†O TH∆Ø M·ª§C models N·∫æU CH∆ØA C√ì
    os.makedirs("models", exist_ok=True)

    # üëâ L∆ØU MODEL V√ÄO FILE best_model.pkl
    model_path = os.path.join("models", "best_model.pkl")
    joblib.dump(best_model, model_path)
    print(f"ƒê√£ l∆∞u model v√†o: {model_path}")

    # D·ª± ƒëo√°n th·ª≠ 1 kh√°ch h√†ng (nh∆∞ c≈©)
    predict_single(best_model)


if __name__ == "__main__":
    main()
